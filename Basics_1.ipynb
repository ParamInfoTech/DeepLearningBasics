{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12.]], shape=(1, 1), dtype=float32)\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],\n",
    "                       [2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "print(product)\n",
    "print(float(product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5. 5.]\n",
      " [5. 5.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor([[3. 3.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "matrix3 = tf.add(matrix1, matrix2)\n",
    "print(matrix3)\n",
    "print(matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction :  tf.Tensor([-2. -1.], shape=(2,), dtype=float32)\n",
      "Result in Numpy Array :  [-2. -1.]\n",
      "Type of Sub is : <class 'tensorflow.python.framework.ops.EagerTensor'> and \n",
      " Type of sub.numpy is : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "sub = tf.subtract(x, a)\n",
    "print(\"Subtraction : \", sub)\n",
    "print(\"Result in Numpy Array : \", sub.numpy())\n",
    "print(\"Type of Sub is : {} and {} Type of sub.numpy is : {}\".\n",
    "      format(type(sub), \"\\n\", type(sub.numpy())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([4., 6.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "y = x\n",
    "print(y)\n",
    "x.assign([4.0, 6.0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples\n",
      "Epoch 1/100\n",
      "398/398 - 1s - loss: 52683.6515\n",
      "Epoch 2/100\n",
      "398/398 - 0s - loss: 3793.5328\n",
      "Epoch 3/100\n",
      "398/398 - 0s - loss: 2442.9920\n",
      "Epoch 4/100\n",
      "398/398 - 0s - loss: 1165.3641\n",
      "Epoch 5/100\n",
      "398/398 - 0s - loss: 661.4885\n",
      "Epoch 6/100\n",
      "398/398 - 0s - loss: 475.7299\n",
      "Epoch 7/100\n",
      "398/398 - 0s - loss: 370.9809\n",
      "Epoch 8/100\n",
      "398/398 - 0s - loss: 320.7081\n",
      "Epoch 9/100\n",
      "398/398 - 0s - loss: 281.2922\n",
      "Epoch 10/100\n",
      "398/398 - 0s - loss: 222.8766\n",
      "Epoch 11/100\n",
      "398/398 - 0s - loss: 181.3272\n",
      "Epoch 12/100\n",
      "398/398 - 0s - loss: 167.0176\n",
      "Epoch 13/100\n",
      "398/398 - 0s - loss: 166.2704\n",
      "Epoch 14/100\n",
      "398/398 - 0s - loss: 167.5344\n",
      "Epoch 15/100\n",
      "398/398 - 0s - loss: 165.4754\n",
      "Epoch 16/100\n",
      "398/398 - 0s - loss: 161.1437\n",
      "Epoch 17/100\n",
      "398/398 - 0s - loss: 165.4451\n",
      "Epoch 18/100\n",
      "398/398 - 0s - loss: 168.3240\n",
      "Epoch 19/100\n",
      "398/398 - 0s - loss: 168.5888\n",
      "Epoch 20/100\n",
      "398/398 - 0s - loss: 164.1849\n",
      "Epoch 21/100\n",
      "398/398 - 0s - loss: 158.4295\n",
      "Epoch 22/100\n",
      "398/398 - 0s - loss: 161.0746\n",
      "Epoch 23/100\n",
      "398/398 - 0s - loss: 163.4399\n",
      "Epoch 24/100\n",
      "398/398 - 0s - loss: 156.7977\n",
      "Epoch 25/100\n",
      "398/398 - 0s - loss: 155.8956\n",
      "Epoch 26/100\n",
      "398/398 - 0s - loss: 153.8746\n",
      "Epoch 27/100\n",
      "398/398 - 0s - loss: 151.0704\n",
      "Epoch 28/100\n",
      "398/398 - 0s - loss: 150.1658\n",
      "Epoch 29/100\n",
      "398/398 - 0s - loss: 150.2106\n",
      "Epoch 30/100\n",
      "398/398 - 0s - loss: 151.1368\n",
      "Epoch 31/100\n",
      "398/398 - 0s - loss: 146.6127\n",
      "Epoch 32/100\n",
      "398/398 - 0s - loss: 146.3690\n",
      "Epoch 33/100\n",
      "398/398 - 0s - loss: 148.5267\n",
      "Epoch 34/100\n",
      "398/398 - 0s - loss: 146.5493\n",
      "Epoch 35/100\n",
      "398/398 - 0s - loss: 143.1989\n",
      "Epoch 36/100\n",
      "398/398 - 0s - loss: 144.1824\n",
      "Epoch 37/100\n",
      "398/398 - 0s - loss: 162.0208\n",
      "Epoch 38/100\n",
      "398/398 - 0s - loss: 150.4635\n",
      "Epoch 39/100\n",
      "398/398 - 0s - loss: 139.4687\n",
      "Epoch 40/100\n",
      "398/398 - 0s - loss: 139.3006\n",
      "Epoch 41/100\n",
      "398/398 - 0s - loss: 143.5715\n",
      "Epoch 42/100\n",
      "398/398 - 0s - loss: 138.0697\n",
      "Epoch 43/100\n",
      "398/398 - 0s - loss: 137.1714\n",
      "Epoch 44/100\n",
      "398/398 - 0s - loss: 135.4718\n",
      "Epoch 45/100\n",
      "398/398 - 0s - loss: 137.1715\n",
      "Epoch 46/100\n",
      "398/398 - 0s - loss: 135.4635\n",
      "Epoch 47/100\n",
      "398/398 - 0s - loss: 136.6384\n",
      "Epoch 48/100\n",
      "398/398 - 0s - loss: 134.6791\n",
      "Epoch 49/100\n",
      "398/398 - 0s - loss: 131.7979\n",
      "Epoch 50/100\n",
      "398/398 - 0s - loss: 135.6791\n",
      "Epoch 51/100\n",
      "398/398 - 0s - loss: 134.3297\n",
      "Epoch 52/100\n",
      "398/398 - 0s - loss: 138.8178\n",
      "Epoch 53/100\n",
      "398/398 - 0s - loss: 131.0954\n",
      "Epoch 54/100\n",
      "398/398 - 0s - loss: 128.7920\n",
      "Epoch 55/100\n",
      "398/398 - 0s - loss: 130.3732\n",
      "Epoch 56/100\n",
      "398/398 - 0s - loss: 127.6238\n",
      "Epoch 57/100\n",
      "398/398 - 0s - loss: 126.7640\n",
      "Epoch 58/100\n",
      "398/398 - 0s - loss: 124.2317\n",
      "Epoch 59/100\n",
      "398/398 - 0s - loss: 123.2595\n",
      "Epoch 60/100\n",
      "398/398 - 0s - loss: 124.4165\n",
      "Epoch 61/100\n",
      "398/398 - 0s - loss: 124.3567\n",
      "Epoch 62/100\n",
      "398/398 - 0s - loss: 129.6410\n",
      "Epoch 63/100\n",
      "398/398 - 0s - loss: 128.4595\n",
      "Epoch 64/100\n",
      "398/398 - 0s - loss: 137.7463\n",
      "Epoch 65/100\n",
      "398/398 - 0s - loss: 126.4211\n",
      "Epoch 66/100\n",
      "398/398 - 0s - loss: 118.7866\n",
      "Epoch 67/100\n",
      "398/398 - 0s - loss: 117.1878\n",
      "Epoch 68/100\n",
      "398/398 - 0s - loss: 117.3575\n",
      "Epoch 69/100\n",
      "398/398 - 0s - loss: 116.1945\n",
      "Epoch 70/100\n",
      "398/398 - 0s - loss: 114.7426\n",
      "Epoch 71/100\n",
      "398/398 - 0s - loss: 113.8942\n",
      "Epoch 72/100\n",
      "398/398 - 0s - loss: 113.6972\n",
      "Epoch 73/100\n",
      "398/398 - 0s - loss: 123.2896\n",
      "Epoch 74/100\n",
      "398/398 - 0s - loss: 116.9563\n",
      "Epoch 75/100\n",
      "398/398 - 0s - loss: 111.7922\n",
      "Epoch 76/100\n",
      "398/398 - 0s - loss: 111.3354\n",
      "Epoch 77/100\n",
      "398/398 - 0s - loss: 110.5203\n",
      "Epoch 78/100\n",
      "398/398 - 0s - loss: 110.3913\n",
      "Epoch 79/100\n",
      "398/398 - 0s - loss: 111.3911\n",
      "Epoch 80/100\n",
      "398/398 - 0s - loss: 119.5164\n",
      "Epoch 81/100\n",
      "398/398 - 0s - loss: 113.3449\n",
      "Epoch 82/100\n",
      "398/398 - 0s - loss: 115.6490\n",
      "Epoch 83/100\n",
      "398/398 - 0s - loss: 115.9368\n",
      "Epoch 84/100\n",
      "398/398 - 0s - loss: 114.4767\n",
      "Epoch 85/100\n",
      "398/398 - 0s - loss: 116.3494\n",
      "Epoch 86/100\n",
      "398/398 - 0s - loss: 107.7643\n",
      "Epoch 87/100\n",
      "398/398 - 0s - loss: 109.9247\n",
      "Epoch 88/100\n",
      "398/398 - 0s - loss: 107.5028\n",
      "Epoch 89/100\n",
      "398/398 - 0s - loss: 102.9338\n",
      "Epoch 90/100\n",
      "398/398 - 0s - loss: 106.1954\n",
      "Epoch 91/100\n",
      "398/398 - 0s - loss: 99.9456\n",
      "Epoch 92/100\n",
      "398/398 - 0s - loss: 100.3129\n",
      "Epoch 93/100\n",
      "398/398 - 0s - loss: 100.2532\n",
      "Epoch 94/100\n",
      "398/398 - 0s - loss: 99.4614\n",
      "Epoch 95/100\n",
      "398/398 - 0s - loss: 106.7805\n",
      "Epoch 96/100\n",
      "398/398 - 0s - loss: 105.0647\n",
      "Epoch 97/100\n",
      "398/398 - 0s - loss: 100.1827\n",
      "Epoch 98/100\n",
      "398/398 - 0s - loss: 98.7683\n",
      "Epoch 99/100\n",
      "398/398 - 0s - loss: 110.0163\n",
      "Epoch 100/100\n",
      "398/398 - 0s - loss: 95.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263ed226c08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (398, 1)\n",
      "Final score (RMSE): 9.722791569388903\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(\"Shape: {}\".format(pred.shape))\n",
    "#print(pred)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Car name: chevrolet chevelle malibu, MPG: 18.0, predicted MPG: [10.384595]\n",
      "2. Car name: buick skylark 320, MPG: 15.0, predicted MPG: [5.92796]\n",
      "3. Car name: plymouth satellite, MPG: 18.0, predicted MPG: [6.854443]\n",
      "4. Car name: amc rebel sst, MPG: 16.0, predicted MPG: [9.544995]\n",
      "5. Car name: ford torino, MPG: 17.0, predicted MPG: [10.245801]\n",
      "6. Car name: ford galaxie 500, MPG: 15.0, predicted MPG: [3.9082608]\n",
      "7. Car name: chevrolet impala, MPG: 14.0, predicted MPG: [-0.6892427]\n",
      "8. Car name: plymouth fury iii, MPG: 14.0, predicted MPG: [1.1794707]\n",
      "9. Car name: pontiac catalina, MPG: 14.0, predicted MPG: [0.59875166]\n",
      "10. Car name: amc ambassador dpl, MPG: 15.0, predicted MPG: [1.3718077]\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. Car name: {cars[i]}, MPG: {y[i]}, predicted MPG: {pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/100\n",
      "150/150 - 1s - loss: 1.2760\n",
      "Epoch 2/100\n",
      "150/150 - 0s - loss: 1.0646\n",
      "Epoch 3/100\n",
      "150/150 - 0s - loss: 0.9616\n",
      "Epoch 4/100\n",
      "150/150 - 0s - loss: 0.9285\n",
      "Epoch 5/100\n",
      "150/150 - 0s - loss: 0.8886\n",
      "Epoch 6/100\n",
      "150/150 - 0s - loss: 0.8451\n",
      "Epoch 7/100\n",
      "150/150 - 0s - loss: 0.8109\n",
      "Epoch 8/100\n",
      "150/150 - 0s - loss: 0.7782\n",
      "Epoch 9/100\n",
      "150/150 - 0s - loss: 0.7425\n",
      "Epoch 10/100\n",
      "150/150 - 0s - loss: 0.7112\n",
      "Epoch 11/100\n",
      "150/150 - 0s - loss: 0.6821\n",
      "Epoch 12/100\n",
      "150/150 - 0s - loss: 0.6494\n",
      "Epoch 13/100\n",
      "150/150 - 0s - loss: 0.6224\n",
      "Epoch 14/100\n",
      "150/150 - 0s - loss: 0.5842\n",
      "Epoch 15/100\n",
      "150/150 - 0s - loss: 0.5476\n",
      "Epoch 16/100\n",
      "150/150 - 0s - loss: 0.5291\n",
      "Epoch 17/100\n",
      "150/150 - 0s - loss: 0.5106\n",
      "Epoch 18/100\n",
      "150/150 - 0s - loss: 0.4876\n",
      "Epoch 19/100\n",
      "150/150 - 0s - loss: 0.4700\n",
      "Epoch 20/100\n",
      "150/150 - 0s - loss: 0.4548\n",
      "Epoch 21/100\n",
      "150/150 - 0s - loss: 0.4385\n",
      "Epoch 22/100\n",
      "150/150 - 0s - loss: 0.4235\n",
      "Epoch 23/100\n",
      "150/150 - 0s - loss: 0.4107\n",
      "Epoch 24/100\n",
      "150/150 - 0s - loss: 0.3978\n",
      "Epoch 25/100\n",
      "150/150 - 0s - loss: 0.3839\n",
      "Epoch 26/100\n",
      "150/150 - 0s - loss: 0.3760\n",
      "Epoch 27/100\n",
      "150/150 - 0s - loss: 0.3637\n",
      "Epoch 28/100\n",
      "150/150 - 0s - loss: 0.3527\n",
      "Epoch 29/100\n",
      "150/150 - 0s - loss: 0.3476\n",
      "Epoch 30/100\n",
      "150/150 - 0s - loss: 0.3321\n",
      "Epoch 31/100\n",
      "150/150 - 0s - loss: 0.3301\n",
      "Epoch 32/100\n",
      "150/150 - 0s - loss: 0.3163\n",
      "Epoch 33/100\n",
      "150/150 - 0s - loss: 0.3091\n",
      "Epoch 34/100\n",
      "150/150 - 0s - loss: 0.2980\n",
      "Epoch 35/100\n",
      "150/150 - 0s - loss: 0.2927\n",
      "Epoch 36/100\n",
      "150/150 - 0s - loss: 0.2830\n",
      "Epoch 37/100\n",
      "150/150 - 0s - loss: 0.2761\n",
      "Epoch 38/100\n",
      "150/150 - 0s - loss: 0.2689\n",
      "Epoch 39/100\n",
      "150/150 - 0s - loss: 0.2635\n",
      "Epoch 40/100\n",
      "150/150 - 0s - loss: 0.2546\n",
      "Epoch 41/100\n",
      "150/150 - 0s - loss: 0.2480\n",
      "Epoch 42/100\n",
      "150/150 - 0s - loss: 0.2394\n",
      "Epoch 43/100\n",
      "150/150 - 0s - loss: 0.2337\n",
      "Epoch 44/100\n",
      "150/150 - 0s - loss: 0.2240\n",
      "Epoch 45/100\n",
      "150/150 - 0s - loss: 0.2182\n",
      "Epoch 46/100\n",
      "150/150 - 0s - loss: 0.2122\n",
      "Epoch 47/100\n",
      "150/150 - 0s - loss: 0.2036\n",
      "Epoch 48/100\n",
      "150/150 - 0s - loss: 0.1991\n",
      "Epoch 49/100\n",
      "150/150 - 0s - loss: 0.1934\n",
      "Epoch 50/100\n",
      "150/150 - 0s - loss: 0.1868\n",
      "Epoch 51/100\n",
      "150/150 - 0s - loss: 0.1823\n",
      "Epoch 52/100\n",
      "150/150 - 0s - loss: 0.1772\n",
      "Epoch 53/100\n",
      "150/150 - 0s - loss: 0.1729\n",
      "Epoch 54/100\n",
      "150/150 - 0s - loss: 0.1686\n",
      "Epoch 55/100\n",
      "150/150 - 0s - loss: 0.1679\n",
      "Epoch 56/100\n",
      "150/150 - 0s - loss: 0.1600\n",
      "Epoch 57/100\n",
      "150/150 - 0s - loss: 0.1560\n",
      "Epoch 58/100\n",
      "150/150 - 0s - loss: 0.1523\n",
      "Epoch 59/100\n",
      "150/150 - 0s - loss: 0.1489\n",
      "Epoch 60/100\n",
      "150/150 - 0s - loss: 0.1454\n",
      "Epoch 61/100\n",
      "150/150 - 0s - loss: 0.1434\n",
      "Epoch 62/100\n",
      "150/150 - 0s - loss: 0.1391\n",
      "Epoch 63/100\n",
      "150/150 - 0s - loss: 0.1379\n",
      "Epoch 64/100\n",
      "150/150 - 0s - loss: 0.1360\n",
      "Epoch 65/100\n",
      "150/150 - 0s - loss: 0.1319\n",
      "Epoch 66/100\n",
      "150/150 - 0s - loss: 0.1306\n",
      "Epoch 67/100\n",
      "150/150 - 0s - loss: 0.1260\n",
      "Epoch 68/100\n",
      "150/150 - 0s - loss: 0.1251\n",
      "Epoch 69/100\n",
      "150/150 - 0s - loss: 0.1221\n",
      "Epoch 70/100\n",
      "150/150 - 0s - loss: 0.1195\n",
      "Epoch 71/100\n",
      "150/150 - 0s - loss: 0.1183\n",
      "Epoch 72/100\n",
      "150/150 - 0s - loss: 0.1156\n",
      "Epoch 73/100\n",
      "150/150 - 0s - loss: 0.1176\n",
      "Epoch 74/100\n",
      "150/150 - 0s - loss: 0.1119\n",
      "Epoch 75/100\n",
      "150/150 - 0s - loss: 0.1100\n",
      "Epoch 76/100\n",
      "150/150 - 0s - loss: 0.1117\n",
      "Epoch 77/100\n",
      "150/150 - 0s - loss: 0.1091\n",
      "Epoch 78/100\n",
      "150/150 - 0s - loss: 0.1053\n",
      "Epoch 79/100\n",
      "150/150 - 0s - loss: 0.1050\n",
      "Epoch 80/100\n",
      "150/150 - 0s - loss: 0.1029\n",
      "Epoch 81/100\n",
      "150/150 - 0s - loss: 0.1063\n",
      "Epoch 82/100\n",
      "150/150 - 0s - loss: 0.1031\n",
      "Epoch 83/100\n",
      "150/150 - 0s - loss: 0.1004\n",
      "Epoch 84/100\n",
      "150/150 - 0s - loss: 0.1021\n",
      "Epoch 85/100\n",
      "150/150 - 0s - loss: 0.0966\n",
      "Epoch 86/100\n",
      "150/150 - 0s - loss: 0.0954\n",
      "Epoch 87/100\n",
      "150/150 - 0s - loss: 0.0976\n",
      "Epoch 88/100\n",
      "150/150 - 0s - loss: 0.0959\n",
      "Epoch 89/100\n",
      "150/150 - 0s - loss: 0.0930\n",
      "Epoch 90/100\n",
      "150/150 - 0s - loss: 0.0936\n",
      "Epoch 91/100\n",
      "150/150 - 0s - loss: 0.0918\n",
      "Epoch 92/100\n",
      "150/150 - 0s - loss: 0.0910\n",
      "Epoch 93/100\n",
      "150/150 - 0s - loss: 0.0911\n",
      "Epoch 94/100\n",
      "150/150 - 0s - loss: 0.0909\n",
      "Epoch 95/100\n",
      "150/150 - 0s - loss: 0.0931\n",
      "Epoch 96/100\n",
      "150/150 - 0s - loss: 0.0871\n",
      "Epoch 97/100\n",
      "150/150 - 0s - loss: 0.0882\n",
      "Epoch 98/100\n",
      "150/150 - 0s - loss: 0.0877\n",
      "Epoch 99/100\n",
      "150/150 - 0s - loss: 0.0858\n",
      "Epoch 100/100\n",
      "150/150 - 0s - loss: 0.0864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263ee629388>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species']) # Classification\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "# Build neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Iris-setosa\n",
      "1         Iris-setosa\n",
      "2         Iris-setosa\n",
      "3         Iris-setosa\n",
      "4         Iris-setosa\n",
      "            ...      \n",
      "145    Iris-virginica\n",
      "146    Iris-virginica\n",
      "147    Iris-virginica\n",
      "148    Iris-virginica\n",
      "149    Iris-virginica\n",
      "Name: species, Length: 150, dtype: object\n",
      "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0              1                0               0\n",
      "1              1                0               0\n",
      "2              1                0               0\n",
      "3              1                0               0\n",
      "4              1                0               0\n",
      "..           ...              ...             ...\n",
      "145            0                0               1\n",
      "146            0                0               1\n",
      "147            0                0               1\n",
      "148            0                0               1\n",
      "149            0                0               1\n",
      "\n",
      "[150 rows x 3 columns]\n",
      "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(df['species'])\n",
    "dummies = pd.get_dummies(df['species']) # Classification\n",
    "print(dummies)\n",
    "species = dummies.columns\n",
    "print(species)\n",
    "y = dummies.values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: {pred.shape}\n",
      "[[9.98692095e-01 1.30742404e-03 4.53485455e-07]\n",
      " [9.96113062e-01 3.88440583e-03 2.46389641e-06]\n",
      " [9.97772276e-01 2.22629891e-03 1.38409541e-06]\n",
      " [9.94566560e-01 5.42888045e-03 4.51339383e-06]\n",
      " [9.98824656e-01 1.17491628e-03 4.13840354e-07]\n",
      " [9.98241305e-01 1.75833004e-03 4.01703261e-07]\n",
      " [9.97337520e-01 2.66080070e-03 1.66683162e-06]\n",
      " [9.97704208e-01 2.29483657e-03 1.01014166e-06]\n",
      " [9.93336320e-01 6.65619830e-03 7.50198888e-06]\n",
      " [9.96285677e-01 3.71201313e-03 2.25824579e-06]\n",
      " [9.99008775e-01 9.90936998e-04 2.29800023e-07]\n",
      " [9.96374071e-01 3.62394680e-03 2.05380070e-06]\n",
      " [9.96512473e-01 3.48521746e-03 2.40921395e-06]\n",
      " [9.97956872e-01 2.04118388e-03 1.94806375e-06]\n",
      " [9.99819219e-01 1.80784526e-04 1.87499296e-08]\n",
      " [9.99687672e-01 3.12309858e-04 3.11822070e-08]\n",
      " [9.99486089e-01 5.13732084e-04 9.33712201e-08]\n",
      " [9.98464584e-01 1.53484102e-03 5.42200667e-07]\n",
      " [9.98532057e-01 1.46770419e-03 2.65504895e-07]\n",
      " [9.98789012e-01 1.21064740e-03 3.53076416e-07]\n",
      " [9.96637940e-01 3.36098671e-03 1.10623057e-06]\n",
      " [9.98295248e-01 1.70417211e-03 5.49996457e-07]\n",
      " [9.99455750e-01 5.43959497e-04 2.20371248e-07]\n",
      " [9.91359234e-01 8.63637496e-03 4.36721621e-06]\n",
      " [9.90213096e-01 9.78038087e-03 6.47672823e-06]\n",
      " [9.92955267e-01 7.04027433e-03 4.48562969e-06]\n",
      " [9.95490849e-01 4.50707413e-03 2.15682758e-06]\n",
      " [9.98347878e-01 1.65149663e-03 5.50006575e-07]\n",
      " [9.98543382e-01 1.45620177e-03 4.97583414e-07]\n",
      " [9.94210243e-01 5.78547455e-03 4.23959455e-06]\n",
      " [9.93393362e-01 6.60190685e-03 4.74049284e-06]\n",
      " [9.97534037e-01 2.46525113e-03 7.53149038e-07]\n",
      " [9.99459565e-01 5.40356734e-04 1.04658611e-07]\n",
      " [9.99696493e-01 3.03575100e-04 3.91733330e-08]\n",
      " [9.95567143e-01 4.43017017e-03 2.73491401e-06]\n",
      " [9.98683155e-01 1.31624227e-03 5.78201195e-07]\n",
      " [9.99281347e-01 7.18550582e-04 1.59887563e-07]\n",
      " [9.98873293e-01 1.12621498e-03 4.26988066e-07]\n",
      " [9.96005595e-01 3.99049930e-03 3.92954780e-06]\n",
      " [9.97867465e-01 2.13171239e-03 8.50767890e-07]\n",
      " [9.98784482e-01 1.21504522e-03 4.47039383e-07]\n",
      " [9.82369125e-01 1.76030081e-02 2.78818188e-05]\n",
      " [9.97220397e-01 2.77733081e-03 2.31660829e-06]\n",
      " [9.94742870e-01 5.25478926e-03 2.39297947e-06]\n",
      " [9.94882822e-01 5.11530135e-03 1.88924321e-06]\n",
      " [9.95035827e-01 4.96053696e-03 3.52550796e-06]\n",
      " [9.98597085e-01 1.40246889e-03 4.25290182e-07]\n",
      " [9.96739805e-01 3.25787556e-03 2.36567325e-06]\n",
      " [9.98932898e-01 1.06686226e-03 2.72872484e-07]\n",
      " [9.97975409e-01 2.02362123e-03 9.13932467e-07]\n",
      " [8.51938326e-04 9.96047318e-01 3.10077448e-03]\n",
      " [1.57815369e-03 9.89854038e-01 8.56781937e-03]\n",
      " [9.58163000e-04 9.75584805e-01 2.34570522e-02]\n",
      " [3.49341077e-03 8.85056436e-01 1.11450166e-01]\n",
      " [1.45150686e-03 9.51119006e-01 4.74294461e-02]\n",
      " [2.65655527e-03 8.52852941e-01 1.44490466e-01]\n",
      " [1.82866515e-03 9.61568356e-01 3.66029479e-02]\n",
      " [1.23824887e-02 9.77703035e-01 9.91440099e-03]\n",
      " [1.17271394e-03 9.87889349e-01 1.09379934e-02]\n",
      " [5.10315038e-03 9.36408758e-01 5.84881753e-02]\n",
      " [5.34290355e-03 9.60948884e-01 3.37082110e-02]\n",
      " [2.66654580e-03 9.80640650e-01 1.66928750e-02]\n",
      " [2.08419468e-03 9.86187458e-01 1.17283827e-02]\n",
      " [1.89612620e-03 8.69903326e-01 1.28200531e-01]\n",
      " [1.06179677e-02 9.84773874e-01 4.60821018e-03]\n",
      " [1.48911797e-03 9.95417356e-01 3.09360144e-03]\n",
      " [3.07644717e-03 8.00064564e-01 1.96859062e-01]\n",
      " [2.49044225e-03 9.90083694e-01 7.42581533e-03]\n",
      " [1.46350462e-03 6.34420156e-01 3.64116341e-01]\n",
      " [2.97547854e-03 9.86200213e-01 1.08243963e-02]\n",
      " [1.88505219e-03 5.54954588e-01 4.43160355e-01]\n",
      " [2.76451558e-03 9.92441535e-01 4.79395501e-03]\n",
      " [8.60480650e-04 4.19808120e-01 5.79331458e-01]\n",
      " [1.76482892e-03 9.10614669e-01 8.76204520e-02]\n",
      " [1.53729646e-03 9.93740082e-01 4.72260173e-03]\n",
      " [1.28652924e-03 9.94544029e-01 4.16953536e-03]\n",
      " [1.01556396e-03 9.61335659e-01 3.76487970e-02]\n",
      " [1.12014497e-03 7.90383041e-01 2.08496869e-01]\n",
      " [2.31119106e-03 9.08526540e-01 8.91622901e-02]\n",
      " [1.59465075e-02 9.79654372e-01 4.39917808e-03]\n",
      " [3.30380909e-03 9.84431922e-01 1.22642703e-02]\n",
      " [4.50917147e-03 9.86918032e-01 8.57276190e-03]\n",
      " [3.20813665e-03 9.90580857e-01 6.21098001e-03]\n",
      " [3.40289029e-04 1.10811345e-01 8.88848364e-01]\n",
      " [3.22634610e-03 6.77854836e-01 3.18918794e-01]\n",
      " [2.49362877e-03 9.75724757e-01 2.17816401e-02]\n",
      " [1.17558241e-03 9.84243155e-01 1.45813366e-02]\n",
      " [1.64099853e-03 9.24068093e-01 7.42909014e-02]\n",
      " [3.30494391e-03 9.85289991e-01 1.14050414e-02]\n",
      " [3.61389061e-03 9.40683722e-01 5.57024553e-02]\n",
      " [2.90633109e-03 7.90298164e-01 2.06795529e-01]\n",
      " [2.01180228e-03 9.43842173e-01 5.41459881e-02]\n",
      " [2.54498352e-03 9.87309396e-01 1.01456773e-02]\n",
      " [1.07267378e-02 9.79385495e-01 9.88781173e-03]\n",
      " [3.20930779e-03 9.38163400e-01 5.86272590e-02]\n",
      " [2.75111315e-03 9.87430453e-01 9.81842726e-03]\n",
      " [2.92184576e-03 9.76329923e-01 2.07483005e-02]\n",
      " [1.75511721e-03 9.90907311e-01 7.33753666e-03]\n",
      " [4.34006900e-02 9.51283932e-01 5.31540206e-03]\n",
      " [2.94606574e-03 9.79817092e-01 1.72368381e-02]\n",
      " [6.38065694e-06 1.45292969e-03 9.98540759e-01]\n",
      " [9.49897658e-05 2.01662984e-02 9.79738712e-01]\n",
      " [3.14779645e-05 2.27631163e-02 9.77205455e-01]\n",
      " [5.71298151e-05 2.09431946e-02 9.78999734e-01]\n",
      " [1.23497448e-05 4.25950205e-03 9.95728076e-01]\n",
      " [3.41209511e-06 3.52629391e-03 9.96470332e-01]\n",
      " [3.17147671e-04 3.04691847e-02 9.69213665e-01]\n",
      " [1.47446235e-05 1.39479870e-02 9.86037314e-01]\n",
      " [1.75184250e-05 8.53852276e-03 9.91443932e-01]\n",
      " [2.06727364e-05 1.44563271e-02 9.85522985e-01]\n",
      " [8.74766207e-04 4.17217940e-01 5.81907272e-01]\n",
      " [1.14208167e-04 4.60119583e-02 9.53873873e-01]\n",
      " [1.14257564e-04 6.53073415e-02 9.34578359e-01]\n",
      " [5.30744328e-05 9.16659273e-03 9.90780294e-01]\n",
      " [2.63734146e-05 4.17646999e-03 9.95797157e-01]\n",
      " [1.37737778e-04 4.76620048e-02 9.52200234e-01]\n",
      " [1.64456593e-04 8.10981393e-02 9.18737411e-01]\n",
      " [1.49273155e-05 1.98445655e-02 9.80140507e-01]\n",
      " [1.04198796e-06 8.31617974e-04 9.99167323e-01]\n",
      " [2.04530676e-04 6.36142567e-02 9.36181247e-01]\n",
      " [4.91845421e-05 2.77882125e-02 9.72162545e-01]\n",
      " [1.55479094e-04 2.68606152e-02 9.72983897e-01]\n",
      " [2.83046256e-06 3.13004875e-03 9.96867120e-01]\n",
      " [7.18783122e-04 2.98242480e-01 7.01038718e-01]\n",
      " [8.35821629e-05 4.38584387e-02 9.56058025e-01]\n",
      " [1.01742458e-04 1.02808036e-01 8.97090197e-01]\n",
      " [1.09932816e-03 4.22222704e-01 5.76677978e-01]\n",
      " [1.10792962e-03 3.89503926e-01 6.09388113e-01]\n",
      " [1.98377074e-05 6.55817287e-03 9.93421972e-01]\n",
      " [2.35934538e-04 2.73284942e-01 7.26479113e-01]\n",
      " [2.45893189e-05 2.54583694e-02 9.74517107e-01]\n",
      " [1.41499229e-04 2.90493757e-01 7.09364712e-01]\n",
      " [1.47928686e-05 4.58059879e-03 9.95404601e-01]\n",
      " [7.71383813e-04 3.89525026e-01 6.09703600e-01]\n",
      " [6.92061367e-05 2.35245749e-02 9.76406157e-01]\n",
      " [2.00417744e-05 2.41913330e-02 9.75788653e-01]\n",
      " [3.40133993e-05 9.70922876e-03 9.90256786e-01]\n",
      " [1.78417496e-04 8.04815143e-02 9.19340134e-01]\n",
      " [1.40587613e-03 4.48186517e-01 5.50407588e-01]\n",
      " [2.85263028e-04 1.86825886e-01 8.12888861e-01]\n",
      " [2.93162830e-05 1.23965321e-02 9.87574160e-01]\n",
      " [5.90617419e-04 3.49824339e-01 6.49585068e-01]\n",
      " [9.49897658e-05 2.01662984e-02 9.79738712e-01]\n",
      " [1.60292911e-05 7.58424029e-03 9.92399752e-01]\n",
      " [2.28061945e-05 9.26812086e-03 9.90709066e-01]\n",
      " [2.24470932e-04 1.04439490e-01 8.95336092e-01]\n",
      " [2.20226473e-04 8.14045295e-02 9.18375194e-01]\n",
      " [3.53347132e-04 1.62388921e-01 8.37257683e-01]\n",
      " [1.07586602e-04 3.06293741e-02 9.69263017e-01]\n",
      " [3.60788283e-04 9.93888080e-02 9.00250435e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(\"Shape: {pred.shape}\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Expected: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "print(f\"Predictions: {predict_classes}\")\n",
    "print(f\"Expected: {expected_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
      "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
      "       'Iris-setosa'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(species[predict_classes[1:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00548343 0.56638    0.42813656]]\n",
      "Predict that [[5. 3. 4. 2.]] is: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "# ad hoc prediction\n",
    "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
    "pred = model.predict(sample_flower)\n",
    "print(pred)\n",
    "pred = np.argmax(pred)\n",
    "print(f\"Predict that {sample_flower} is: {species[pred]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.4834341e-03 5.6638002e-01 4.2813656e-01]\n",
      " [9.9530715e-01 4.6911249e-03 1.7126314e-06]]\n",
      "Predict that these two flowers [[5.  3.  4.  2. ]\n",
      " [5.2 3.5 1.5 0.8]] are: Index(['Iris-versicolor', 'Iris-setosa'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# predict two sample flowers\n",
    "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
    "pred = model.predict(sample_flower)\n",
    "print(pred)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(f\"Predict that these two flowers {sample_flower} are: {species[pred]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
